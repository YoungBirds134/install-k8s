{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType \n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import col,array_contains\n",
    "import matplotlib.pyplot as plt\n",
    "#import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import os\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Thierry Bertin-Mahieux (2010) Columbia University\n",
    "tb2332@columbia.edu\n",
    "\n",
    "\n",
    "This code contains a set of getters functions to access the fields\n",
    "from an HDF5 song file (regular file with one song or\n",
    "aggregate / summary file with many songs)\n",
    "\n",
    "This is part of the Million Song Dataset project from\n",
    "LabROSA (Columbia University) and The Echo Nest.\n",
    "\n",
    "\n",
    "Copyright 2010, Thierry Bertin-Mahieux\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import tables\n",
    "\n",
    "\n",
    "def open_h5_file_read(h5filename):\n",
    "    \"\"\"\n",
    "    Open an existing H5 in read mode.\n",
    "    Same function as in hdf5_utils, here so we avoid one import\n",
    "    \"\"\"\n",
    "    return tables.openFile(h5filename, mode='r')\n",
    "\n",
    "\n",
    "def get_num_songs(h5):\n",
    "    \"\"\"\n",
    "    Return the number of songs contained in this h5 file, i.e. the number of rows\n",
    "    for all basic informations like name, artist, ...\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.nrows\n",
    "\n",
    "def get_artist_familiarity(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist familiarity from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_familiarity[songidx]\n",
    "\n",
    "def get_artist_hotttnesss(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist hotttnesss from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_hotttnesss[songidx]\n",
    "\n",
    "def get_artist_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_id[songidx]\n",
    "\n",
    "def get_artist_mbid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musibrainz id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_mbid[songidx]\n",
    "\n",
    "def get_artist_playmeid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist playme id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_playmeid[songidx]\n",
    "\n",
    "def get_artist_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_7digitalid[songidx]\n",
    "\n",
    "def get_artist_latitude(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist latitude from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_latitude[songidx]\n",
    "\n",
    "def get_artist_longitude(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist longitude from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_longitude[songidx]\n",
    "\n",
    "def get_artist_location(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist location from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_location[songidx]\n",
    "\n",
    "def get_artist_name(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist name from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_name[songidx]\n",
    "\n",
    "def get_release(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.release[songidx]\n",
    "\n",
    "def get_release_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.release_7digitalid[songidx]\n",
    "\n",
    "def get_song_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.song_id[songidx]\n",
    "\n",
    "def get_song_hotttnesss(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song hotttnesss from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.song_hotttnesss[songidx]\n",
    "\n",
    "def get_title(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get title from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.title[songidx]\n",
    "\n",
    "def get_track_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get track 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.track_7digitalid[songidx]\n",
    "\n",
    "def get_similar_artists(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get similar artists array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:]\n",
    "    return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:\n",
    "                                            h5.root.metadata.songs.cols.idx_similar_artists[songidx+1]]\n",
    "\n",
    "def get_artist_terms(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist terms array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n",
    "    return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n",
    "                                            h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n",
    "\n",
    "def get_artist_terms_freq(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n",
    "    return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n",
    "                                              h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n",
    "\n",
    "def get_artist_terms_weight(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n",
    "    return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n",
    "                                                h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n",
    "\n",
    "def get_analysis_sample_rate(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get analysis sample rate from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.analysis_sample_rate[songidx]\n",
    "\n",
    "def get_audio_md5(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get audio MD5 from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.audio_md5[songidx]\n",
    "\n",
    "def get_danceability(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get danceability from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.danceability[songidx]\n",
    "\n",
    "def get_duration(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get duration from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.duration[songidx]\n",
    "\n",
    "def get_end_of_fade_in(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get end of fade in from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.end_of_fade_in[songidx]\n",
    "\n",
    "def get_energy(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get energy from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.energy[songidx]\n",
    "\n",
    "def get_key(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get key from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.key[songidx]\n",
    "\n",
    "def get_key_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get key confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.key_confidence[songidx]\n",
    "\n",
    "def get_loudness(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get loudness from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.loudness[songidx]\n",
    "\n",
    "def get_mode(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get mode from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.mode[songidx]\n",
    "\n",
    "def get_mode_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get mode confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.mode_confidence[songidx]\n",
    "\n",
    "def get_start_of_fade_out(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get start of fade out from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.start_of_fade_out[songidx]\n",
    "\n",
    "def get_tempo(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tempo from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.tempo[songidx]\n",
    "\n",
    "def get_time_signature(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get signature from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.time_signature[songidx]\n",
    "\n",
    "def get_time_signature_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get signature confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.time_signature_confidence[songidx]\n",
    "\n",
    "def get_track_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get track id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.track_id[songidx]\n",
    "\n",
    "def get_segments_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:]\n",
    "    return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:\n",
    "                                           h5.root.analysis.songs.cols.idx_segments_start[songidx+1]]\n",
    "    \n",
    "def get_segments_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:]\n",
    "    return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:\n",
    "                                                h5.root.analysis.songs.cols.idx_segments_confidence[songidx+1]]\n",
    "\n",
    "def get_segments_pitches(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments pitches array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:,:]\n",
    "    return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:\n",
    "                                             h5.root.analysis.songs.cols.idx_segments_pitches[songidx+1],:]\n",
    "\n",
    "def get_segments_timbre(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments timbre array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:,:]\n",
    "    return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:\n",
    "                                            h5.root.analysis.songs.cols.idx_segments_timbre[songidx+1],:]\n",
    "\n",
    "def get_segments_loudness_max(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments loudness max array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:]\n",
    "    return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:\n",
    "                                                  h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx+1]]\n",
    "\n",
    "def get_segments_loudness_max_time(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments loudness max time array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:]\n",
    "    return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:\n",
    "                                                       h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx+1]]\n",
    "\n",
    "def get_segments_loudness_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments loudness start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:]\n",
    "    return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:\n",
    "                                                    h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx+1]]\n",
    "\n",
    "def get_sections_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get sections start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:]\n",
    "    return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:\n",
    "                                           h5.root.analysis.songs.cols.idx_sections_start[songidx+1]]\n",
    "\n",
    "def get_sections_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get sections confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:]\n",
    "    return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:\n",
    "                                                h5.root.analysis.songs.cols.idx_sections_confidence[songidx+1]]\n",
    "\n",
    "def get_beats_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get beats start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:]\n",
    "    return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:\n",
    "                                        h5.root.analysis.songs.cols.idx_beats_start[songidx+1]]\n",
    "\n",
    "def get_beats_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get beats confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:]\n",
    "    return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:\n",
    "                                             h5.root.analysis.songs.cols.idx_beats_confidence[songidx+1]]\n",
    "\n",
    "def get_bars_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get bars start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:]\n",
    "    return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:\n",
    "                                       h5.root.analysis.songs.cols.idx_bars_start[songidx+1]]\n",
    "\n",
    "def get_bars_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get bars start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:]\n",
    "    return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:\n",
    "                                            h5.root.analysis.songs.cols.idx_bars_confidence[songidx+1]]\n",
    "\n",
    "def get_tatums_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tatums start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:]\n",
    "    return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:\n",
    "                                         h5.root.analysis.songs.cols.idx_tatums_start[songidx+1]]\n",
    "\n",
    "def get_tatums_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tatums confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:]\n",
    "    return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:\n",
    "                                              h5.root.analysis.songs.cols.idx_tatums_confidence[songidx+1]]\n",
    "\n",
    "def get_artist_mbtags(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n",
    "        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n",
    "    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n",
    "                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n",
    "\n",
    "def get_artist_mbtags_count(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musicbrainz tag count array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n",
    "        return h5.root.musicbrainz.artist_mbtags_count[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n",
    "    return h5.root.musicbrainz.artist_mbtags_count[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n",
    "                                                   h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n",
    "\n",
    "def get_year(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release year from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.musicbrainz.songs.cols.year[songidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "# Đường dẫn đến thư mục chứa các tập tin .h5\n",
    "folder_path = './MillionSongSubset'\n",
    "\n",
    "# Hàm để đọc dữ liệu từ tập tin .h5\n",
    "def read_h5_file(file_path, csv_writer):\n",
    "        h5 = open_h5_file_read(file_path)\n",
    "        #print(h5)\n",
    "        #c = csv.writer(open(\"data.csv\", \"w+\"))\n",
    "        #all_artist_id = []\n",
    "        all_artist_names = []\n",
    "        all_songs_id = []\n",
    "        all_songs_names = []\n",
    "        all_tempo = []\n",
    "        all_loudness = []\n",
    "        all_key_confidence = []\n",
    "        all_mode_confidence = []\n",
    "        all_song_hottness=[]\n",
    "        all_year =[]\n",
    "        artist_id = get_artist_id(h5)\n",
    "        print(artist_id)\n",
    "        all_artist_id.append(artist_id)\n",
    "        artist_name = get_artist_name(h5)\n",
    "        all_artist_names.append(artist_name)\n",
    "        song_id = get_song_id(h5)\n",
    "        all_songs_id.append(song_id)\n",
    "        song_name = get_title(h5)\n",
    "        all_songs_names.append(song_name)\n",
    "        loudness = get_loudness(h5)\n",
    "        all_loudness.append(loudness)\n",
    "        song_hottness = get_song_hotttnesss(h5)\n",
    "        all_song_hottness.append(song_hottness)\n",
    "        tempo = get_tempo(h5)\n",
    "        all_tempo.append(tempo)\n",
    "        key_confidence = get_key_confidence(h5)\n",
    "        all_key_confidence.append(key_confidence)\n",
    "        mode_confidence = get_mode_confidence(h5)\n",
    "        all_mode_confidence.append(mode_confidence)\n",
    "        year= get_year(h5)\n",
    "        all_year.append(year)\n",
    "        for k in range(len(list(all_artist_names))):\n",
    "           artist_id=list(all_artist_id)[k]\n",
    "           artist_name=list(all_artist_names)[k]\n",
    "           song_id=list(all_songs_id)[k]\n",
    "           song_name=list(all_songs_names)[k]\n",
    "           loudness=list(all_loudness)[k]\n",
    "           tempo=list(all_tempo)[k]\n",
    "           key_confidence=list(all_key_confidence)[k]\n",
    "           mode_confidence=list(all_mode_confidence)[k]\n",
    "           year=list(all_year)[k]\n",
    "           print([artist_id,artist_name, song_id, song_name,loudness, tempo,key_confidence, mode_confidence, year])\n",
    "           csv_writer.writerow([artist_id,artist_name, song_id, song_name,loudness, tempo,key_confidence, mode_confidence, year])\n",
    "\n",
    "           #c.writerow([artist_id, artist_name, song_id, song_name,loudness, tempo,key_confidence, mode_confidence, year])\n",
    "\n",
    "\n",
    "                # Ghi dữ liệu vào tệp CSV\n",
    "\n",
    "# Tạo tệp CSV cho việc ghi dữ liệu\n",
    "with open(\"data.csv\", \"w+\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    #csv_writer.writerow(['Artist ID', 'Artist Name', 'Song ID', 'Song Name',\n",
    "    #                     'Loudness', 'Song Hottness', 'Tempo', 'Year'])\n",
    "    \n",
    "    # Lặp qua tất cả các tập tin .h5 trong thư mục\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.h5'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                read_h5_file(file_path, csv_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scala_version = '2.12'\n",
    "spark_version = '3.1.2'\n",
    "# TODO: Ensure match above values match the correct versions\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.2.1'\n",
    "]\n",
    "# tạo  Spark session\n",
    "sc = SparkSession.builder \\\n",
    "    .appName(\"Song\") \\\n",
    "    .config(\"spark.driver.allowMultipleContexts\", \"true\") \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:9000/hive\") \\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages))\\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "  step1=sc.textFile(\"file:///output_csv.csv\")\n",
    "  step2=step1.map(lambda line:  line.split(\",\")).filter(lambda line:\n",
    "  len(line)>1)\n",
    "  step3=step2.map(lambda line:  ((str(line[1].encode(‘utf-8’)),\n",
    "    str(line[0].encode(‘utf-8’)))))\n",
    "  step4=step2.map(lambda line:  ((line[1].encode(‘utf-8’),\n",
    "    line[0].encode(‘utf-8’),float(line[4]),int(line[9])))).distinct()\n",
    "  for i in range (10)\n",
    "    inp_year = 1990 + i\n",
    "    step5=step4.filter(lambda line:  line[3]==inp_year).map(lambda\n",
    "       line:  ((float(line[2]),(line[0],line[1],line[3]))))\n",
    "    step6=step5.sortByKey(False)\n",
    "    #Emit top 10 artists\n",
    "    topArtists=step6.take(10)\n",
    "    step8=step2.map(lambda line:  ((line[3].encode(‘utf-8’),\n",
    "          line[2].encode(‘utf-8’),float(line[5]),int(line[9])))).distinct()\n",
    "    step9=step8.filter(lambda line:  line[3]==inp_year).map(lambda line:\n",
    "          ((float(line[2]),(line[0],line[1],line[3])))).filter(lambda  line:  not math.isnan(line[0]))\n",
    "   step10=step9.sortByKey(False)\n",
    "   #Emit top 10 songs\n",
    "   topSongs=step10.take(10)\n",
    "sc.stop"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
